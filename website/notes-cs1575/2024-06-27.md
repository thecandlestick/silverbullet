---
tags:
  - cs1575LN
date: {}
---
#cs1575LN
|  |  |  |  |
|----------|----------|----------|----------|
| [[CS1575|Home]] | [[CS1575 Calendar|Calendar]] | [[CS1575 Syllabus|Syllabus]] | [[Lecture Notes]] |


## Reminders

```query
cs1575task
where done = false
render [[template/topic]]
```

## Objectives

```query
task
where page = "CS1575 Calendar" and done = false
limit 3
order by pos
render [[template/topic]]
```
---

* [x] [[PA03]]  ðŸ“…2024-07-05 #cs1575task


# Intro to Algorithm Complexity

---
## Comparing Rate-of-Growth

Now that we have a way of representing algorithms as programs, we need a way of comparing them. As relying on our intuition to decide which is function is _better_ can be misleading.

![](../img%2Frt-smallscale.png)
_ENHANCE!_

![](../img%2Frt-largescale.png)

What we really value in algorithms is how well they _scale_ for large inputs. This due to a relatively simple law of algorithms: 
  
_For small inputs, the differences between Algo A and Algo B will generally be small as well. For large inputs the differences can be much greater, sometimes exponentially so!_ 

The essential characteristic we need to extract from these functions is their **rate-of-growth**. Luckily, we have a collection of mathematical tools to do just that.

**Definition: (Big-O Notation)**

```latex
\text{Given functions f(x) and g(x),}\\
\text{we say that f(x) is O(g(x)) if and only if there exist positive constants C and }n_0\\
\text{such that for every }n > n_0, f(n) \leq C*g(n)
```

f(n) = 2n + 5
g(n) = 3n + 2

Human-readable format:

```latex
\text{"f(x) is O(g(x))" means that the rate-of-growth of g(x) is}\\ \text{greater than or equal to the rate of growth of f(x),}\\ \text{when ignoring constant factors}
```

The key to proving these properties is to remember that you can choose any positive constants that make the inequality true for a sufficiently large n value.

The key to disproving these properties is to let C represent some arbitrarily high number, and then show that the inequality always becomes false for a sufficiently large n value.

[[examples/big-oh-basics]]

n^2 is O(3n^2 + n)
f(n) = n^2
g(n) = 3n^2 + n

3n^2 + n is O(n^2)

* [ ] rae, brileigh  ðŸ“…2024-06-27 #cs1575EC


**Definition: (Big-theta Notation)**

```latex
\text{Given functions f(x) and g(x),}\\
\text{we say that f(x) is Î˜(g(x)) if and only if there exist positive constants}\\
C_1, C_2, n_0\text{ such that for every }n > n_0, C_1*g(n) \leq f(n) \leq C_2*g(n)
```

Equivalently:

```latex
\text{If f(x) is O(g(x)) and g(x) is O(f(x)),}\\
\Rightarrow \text{f(x) is Î˜(g(x)) and g(x) is Î˜(f(x))}
```

Human-readable format:

```latex
\text{"f(x) is Î˜(g(x))" means that the rate-of-growth of g(x) is}\\
\text{equal to the rate of growth of f(x),}\\
\text{when ignoring constant factors}
```

---
## The Complexity Hierarchy

The concept of Big-Î˜ notation is particularly important because it allows us to further simply our analysis. If we can prove that f(x) is Î˜(g(x)), then f(x) is equivalent in performance to any other function that is also Î˜(g(x)).

This allows us to classify functions by their simple-and-easy-to-work-with equivalents, giving rise to the _Complexity Hierarchy_

| Complexity | Name |
|----------|----------|
| n! | factorial |
| 2^n | exponential |
| ... | ... |
| n^a | polynomial |
| n^3 | cubic |
| n^2 | quadratic |
| n*log(n) | linearithmic |
| n | linear |
| log(n) | logarithmic |
| 1 | constant |

Every runtime function is Î˜ to only one layer of the hierarchy, and each layer represents dramatically better performance than those that come above it. 

From the formal definition of Big-O and Big-theta, we can prove some useful theorems that we can use to map a large, unruly function into its place in the complexity hierarchy. 

If T1(n) is O(f(n)) and T2(n) is O(g(n)), then:
* T1(n) + T2(n) is O( max(f(n), g(n)) )
* T1(n) * T2(n) is O( f(n)*g(n) )

(3n^3) + (2n^2) - ((15n)*(lg(n)))

And from those theorems:
* A polynomial of degree k is O( n^k )

an^k + bn^k-1 + cn^k-2 + ... + z(n^0) is O(n^k)

4n^7 + 3n^5 - 20n^2 + 3,000,000 is O(n^7)

**Note: The theorems above also work for big-Î˜**

* [ ] brileigh  ðŸ“…2024-06-27 #cs1575EC

---
## Complexity & Data Structures

For the following comparison, assume that both lists accept a ListIterator to access data with operations:
* prev() - move to previous data element
* next() - move to next data element
* moveTo(i) - move to element i

For get, insert, erase, assume that you have a valid ListIterator

| Operation | ArrayList | LinkedList |
|----------|----------|----------|
| get | O(1) | O(1) |
| prev | O(?) | O(?) |
| next | O(?) | O(?) |
| moveTo | O(?) | O(?) |
| insert | O(?) | O(?) |
| erase | O(?) | O(?) |


What conclusions can you draw about which list to use?

_KC:
Fill in the table above for a Doubly-LinkedList. A Doubly-LinkedList uses nodes that store the memory address of the next and the previous node_


